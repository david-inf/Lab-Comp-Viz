{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3015,  0.7135, -1.7389,  1.6651,  2.3736],\n",
      "        [-1.8491, -1.1479,  0.5863, -0.5880,  1.9614],\n",
      "        [ 0.2790,  0.9023, -0.2384,  1.0261,  1.0308]])\n",
      "tensor([[ 0.1592,  0.4390, -0.9397,  0.8153,  0.7310],\n",
      "        [-0.9762, -0.7064,  0.3168, -0.2879,  0.6041],\n",
      "        [ 0.1473,  0.5552, -0.1288,  0.5024,  0.3175]])\n",
      "tensor([[ 0.0869,  0.2057, -0.5013,  0.4801,  0.6843],\n",
      "        [-0.6072, -0.3770,  0.1925, -0.1931,  0.6441],\n",
      "        [ 0.1594,  0.5154, -0.1362,  0.5862,  0.5889]])\n"
     ]
    }
   ],
   "source": [
    "z1 = torch.randn(3, 5)\n",
    "z2 = torch.randn(3, 5)\n",
    "\n",
    "z1_n0 = F.normalize(z1, dim=0)\n",
    "z2_n0 = F.normalize(z2, dim=0)\n",
    "\n",
    "z1_n1 = F.normalize(z1, dim=1)\n",
    "z2_n1 = F.normalize(z2, dim=1)\n",
    "\n",
    "print(z1)\n",
    "print(z1_n0)\n",
    "print(z1_n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3341,  0.7255,  1.7563, -1.8413,  0.3239],\n",
      "        [ 0.9806,  0.3093,  2.6667, -1.2414, -0.4104],\n",
      "        [-2.0712, -0.1347, -4.6917,  1.3817, -0.2528],\n",
      "        [ 1.5604,  0.0108,  4.8011, -1.1641, -0.5229],\n",
      "        [ 0.6905, -1.1013,  5.3146,  0.8950, -1.1448]])\n",
      "tensor([[ 0.5229,  0.8400,  0.3626, -0.8842,  0.1665],\n",
      "        [ 0.4481,  0.4175,  0.6417, -0.6948, -0.2458],\n",
      "        [-0.8311, -0.1596, -0.9915,  0.6791, -0.1330],\n",
      "        [ 0.5673,  0.0116,  0.9193, -0.5184, -0.2492],\n",
      "        [ 0.1579, -0.7439,  0.6401,  0.2507, -0.3431]])\n",
      "tensor([[ 0.2467,  0.1689,  0.3485, -0.4142,  0.0099],\n",
      "        [ 0.0212,  0.0465,  0.4810, -0.2055, -0.3179],\n",
      "        [-0.2206, -0.0346, -0.5644,  0.2022,  0.0346],\n",
      "        [ 0.0073, -0.0254,  0.6834, -0.1127, -0.3967],\n",
      "        [-0.3102, -0.2932,  0.5637,  0.4412, -0.5676]])\n"
     ]
    }
   ],
   "source": [
    "print(z1.T @ z2)\n",
    "print(z1_n0.T @ z2_n0)\n",
    "print(z1_n1.T @ z2_n1)\n",
    "\n",
    "c = z1_n0.T @ z2_n0 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def off_diagonal(x):\n",
    "    # return a flattened view of the off-diagonal elements of a square matrix\n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5079)\n"
     ]
    }
   ],
   "source": [
    "invariance = torch.diagonal(c).add_(-1).pow_(2).sum()\n",
    "redundancy_reduction = off_diagonal(c).pow_(2).sum()\n",
    "loss = invariance + redundancy_reduction\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6818,  0.2800,  0.1209, -0.2947,  0.0555],\n",
      "        [ 0.1494,  0.7410,  0.2139, -0.2316, -0.0819],\n",
      "        [-0.2770, -0.0532,  1.7702,  0.2264, -0.0443],\n",
      "        [ 0.1891,  0.0039,  0.3064,  1.3755, -0.0831],\n",
      "        [ 0.0526, -0.2480,  0.2134,  0.0836,  1.2418]])\n",
      "tensor([[ 0.3409,  0.1400,  0.0604, -0.1474,  0.0277],\n",
      "        [ 0.0747,  0.3705,  0.1070, -0.1158, -0.0410],\n",
      "        [-0.1385, -0.0266,  0.8851,  0.1132, -0.0222],\n",
      "        [ 0.0945,  0.0019,  0.1532,  0.6877, -0.0415],\n",
      "        [ 0.0263, -0.1240,  0.1067,  0.0418,  0.6209]])\n"
     ]
    }
   ],
   "source": [
    "print(c)\n",
    "c.div_(2)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from nets import SiameseNetSync\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'x2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m input_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m SiameseNetSync(resnet18())\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Utente\\anaconda3\\envs\\torch-wb2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Utente\\anaconda3\\envs\\torch-wb2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x2'"
     ]
    }
   ],
   "source": [
    "input_data = torch.rand(1,3,32,32)\n",
    "model = SiameseNetSync(resnet18())\n",
    "model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utente\\anaconda3\\envs\\torch-wb2\\lib\\site-packages\\onnxscript\\converter.py:820: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n",
      "c:\\Users\\Utente\\anaconda3\\envs\\torch-wb2\\lib\\site-packages\\onnxscript\\converter.py:820: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `MyModel([...]` with `torch.export.export`...\n",
      "[torch.onnx] Obtain model graph for `MyModel([...]` with `torch.export.export`... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=9,\n",
       "            opset_imports={'': 18, 'pkg.onnxscript.torch_lib.common': 1},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.5.1',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"input\"<FLOAT,[1,1,128,128]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"relu\"<FLOAT,[1,128,124,124]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"conv1.weight\"<FLOAT,[128,1,5,5]>,\n",
       "                %\"conv1.bias\"<FLOAT,[128]>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # node_Conv_0\n",
       "                 %\"convolution\"<FLOAT,[1,128,124,124]> ⬅️ ::Conv(%\"input\", %\"conv1.weight\", %\"conv1.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[0, 0, 0, 0], strides=[1, 1]}\n",
       "            1 |  # node_Relu_1\n",
       "                 %\"relu\"<FLOAT,[1,128,124,124]> ⬅️ ::Relu(%\"convolution\")\n",
       "            return %\"relu\"<FLOAT,[1,128,124,124]>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib.common::Rank(\n",
       "            inputs=(\n",
       "                %\"input\"<?,?>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"return_val\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # n0\n",
       "                 %\"tmp\"<?,?> ⬅️ ::Shape(%\"input\")\n",
       "            1 |  # n1\n",
       "                 %\"return_val\"<?,?> ⬅️ ::Size(%\"tmp\")\n",
       "            return %\"return_val\"<?,?>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib.common::IsScalar(\n",
       "            inputs=(\n",
       "                %\"input\"<?,?>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"return_val\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # n0\n",
       "                 %\"tmp\"<?,?> ⬅️ ::Shape(%\"input\")\n",
       "            1 |  # n1\n",
       "                 %\"tmp_0\"<?,?> ⬅️ ::Size(%\"tmp\")\n",
       "            2 |  # n2\n",
       "                 %\"tmp_1\"<?,?> ⬅️ ::Constant() {value_int=0}\n",
       "            3 |  # n3\n",
       "                 %\"return_val\"<?,?> ⬅️ ::Equal(%\"tmp_0\", %\"tmp_1\")\n",
       "            return %\"return_val\"<?,?>\n",
       "        }\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_conv1_weight: \"f32[128, 1, 5, 5]\", p_conv1_bias: \"f32[128]\", x: \"f32[1, 1, 128, 128]\"):\n",
       "                     # File: C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_11320\\1588012940.py:9 in forward, code: return torch.relu(self.conv1(x))\n",
       "                    convolution: \"f32[1, 128, 124, 124]\" = torch.ops.aten.convolution.default(x, p_conv1_weight, p_conv1_bias, [1, 1], [0, 0], [1, 1], False, [0, 0], 1);  x = p_conv1_weight = p_conv1_bias = None\n",
       "                    relu: \"f32[1, 128, 124, 124]\" = torch.ops.aten.relu.default(convolution);  convolution = None\n",
       "                    return (relu,)\n",
       "            \n",
       "        Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_conv1_weight'), target='conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_conv1_bias'), target='conv1.bias', persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='relu'), target=None)])\n",
       "        Range constraints: {}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.rand((1, 1, 128, 128), dtype=torch.float32)\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,                  # model to export\n",
    "    (input_tensor,),        # inputs of the model,\n",
    "    \"my_model.onnx\",        # filename of the ONNX model\n",
    "    input_names=[\"input\"],  # Rename inputs for the ONNX model\n",
    "    dynamo=True             # True or False to select the exporter to use\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-wb2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
