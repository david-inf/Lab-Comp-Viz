{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da617566-e649-4687-99f4-f1d5e224fc9c",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ac5a46-42fb-4a45-88f7-99fc77312f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchinfo import summary\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31e732e0-7fd0-4c6f-b361-6d658780b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "from lab1_utils import train, test, get_lr\n",
    "from lab1_utils import multiple_diagnostic, test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "063715bf-fcc8-40e7-9d58-4380ab92245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1bf375e-5a56-4c44-8f23-f5778b61e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 64\n",
    "batch_size = 128\n",
    "max_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0817ce9e-ba04-4a23-8944-be73d88663ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # some augmentation\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "# create a split for train/validation. We can use early stop\n",
    "trainset, valset = torch.utils.data.random_split(dataset, [40000, 10000])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2,\n",
    "                                          drop_last=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2,\n",
    "                                          drop_last=False)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2,\n",
    "                                          drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "608ecb7c-7623-4932-8a72-8c449e9c9dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train_loader, test_loader, model, criterion, device,\n",
    "               lr, momentum, max_epochs, do_test=True):\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=1e-4)\n",
    "\n",
    "    losses_train, accs_train = [], []\n",
    "    losses_test, accs_test = [], []\n",
    "    \n",
    "    _start = time.time()\n",
    "    _epoch_time = time.time()\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        loss_train, acc_train = train(model, device, train_loader, criterion, optimizer)\n",
    "        print(f\"Epoch: {epoch}, Learning rate: {get_lr(optimizer):.6f}\")\n",
    "        print(f\"Training - Loss: {loss_train:.4f}, Accuracy: {acc_train:.2f}, Runtime: {(time.time() - _epoch_time):.2f}\")\n",
    "        losses_train.append(loss_train)\n",
    "        accs_train.append(acc_train)\n",
    "\n",
    "        if do_test:\n",
    "            loss_test, acc_test = test(model, device, criterion, test_loader)\n",
    "            losses_test.append(loss_test)\n",
    "            accs_test.append(acc_test)\n",
    "            print(f\"Test - Loss: {loss_test:.4f}, Accuracy: {acc_test:.2f}\")\n",
    "\n",
    "        _epoch_time = time.time()\n",
    "\n",
    "    _end = time.time()\n",
    "    print(f\"Done! - Runtime: {(_end-_start):.2f} seconds\")\n",
    "\n",
    "    # test_class(model, device, criterion, testloader)\n",
    "\n",
    "    if do_test:\n",
    "        return losses_train, accs_train, losses_test, accs_test\n",
    "    else:\n",
    "        return losses_train, accs_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f03c2-0ee3-48d0-bb6a-7f97ca7cecc1",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Scegliamo di usare `resnet18`\n",
    "\n",
    "Due prove di fine-tuning:\n",
    "- Modificare il layer finale di classificazione `resnet18_1` partendo dai pesi originali cercando di arrivare alle migliori performance possibili\n",
    "- Mettere in coda un MLP `resnet18_2`\n",
    "- Riaddestrare un layer precedente `resnet18_3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed0b63-24e2-4efc-89d5-d06c9c25ecad",
   "metadata": {},
   "source": [
    "## Classification head: linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93750a13-ef9f-4bb3-aaf2-5a0d59fa9d72",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResNet                                   --\n",
      "├─Conv2d: 1-1                            9,408\n",
      "├─BatchNorm2d: 1-2                       128\n",
      "├─ReLU: 1-3                              --\n",
      "├─MaxPool2d: 1-4                         --\n",
      "├─Sequential: 1-5                        --\n",
      "│    └─BasicBlock: 2-1                   --\n",
      "│    │    └─Conv2d: 3-1                  36,864\n",
      "│    │    └─BatchNorm2d: 3-2             128\n",
      "│    │    └─ReLU: 3-3                    --\n",
      "│    │    └─Conv2d: 3-4                  36,864\n",
      "│    │    └─BatchNorm2d: 3-5             128\n",
      "│    └─BasicBlock: 2-2                   --\n",
      "│    │    └─Conv2d: 3-6                  36,864\n",
      "│    │    └─BatchNorm2d: 3-7             128\n",
      "│    │    └─ReLU: 3-8                    --\n",
      "│    │    └─Conv2d: 3-9                  36,864\n",
      "│    │    └─BatchNorm2d: 3-10            128\n",
      "├─Sequential: 1-6                        --\n",
      "│    └─BasicBlock: 2-3                   --\n",
      "│    │    └─Conv2d: 3-11                 73,728\n",
      "│    │    └─BatchNorm2d: 3-12            256\n",
      "│    │    └─ReLU: 3-13                   --\n",
      "│    │    └─Conv2d: 3-14                 147,456\n",
      "│    │    └─BatchNorm2d: 3-15            256\n",
      "│    │    └─Sequential: 3-16             8,448\n",
      "│    └─BasicBlock: 2-4                   --\n",
      "│    │    └─Conv2d: 3-17                 147,456\n",
      "│    │    └─BatchNorm2d: 3-18            256\n",
      "│    │    └─ReLU: 3-19                   --\n",
      "│    │    └─Conv2d: 3-20                 147,456\n",
      "│    │    └─BatchNorm2d: 3-21            256\n",
      "├─Sequential: 1-7                        --\n",
      "│    └─BasicBlock: 2-5                   --\n",
      "│    │    └─Conv2d: 3-22                 294,912\n",
      "│    │    └─BatchNorm2d: 3-23            512\n",
      "│    │    └─ReLU: 3-24                   --\n",
      "│    │    └─Conv2d: 3-25                 589,824\n",
      "│    │    └─BatchNorm2d: 3-26            512\n",
      "│    │    └─Sequential: 3-27             33,280\n",
      "│    └─BasicBlock: 2-6                   --\n",
      "│    │    └─Conv2d: 3-28                 589,824\n",
      "│    │    └─BatchNorm2d: 3-29            512\n",
      "│    │    └─ReLU: 3-30                   --\n",
      "│    │    └─Conv2d: 3-31                 589,824\n",
      "│    │    └─BatchNorm2d: 3-32            512\n",
      "├─Sequential: 1-8                        --\n",
      "│    └─BasicBlock: 2-7                   --\n",
      "│    │    └─Conv2d: 3-33                 1,179,648\n",
      "│    │    └─BatchNorm2d: 3-34            1,024\n",
      "│    │    └─ReLU: 3-35                   --\n",
      "│    │    └─Conv2d: 3-36                 2,359,296\n",
      "│    │    └─BatchNorm2d: 3-37            1,024\n",
      "│    │    └─Sequential: 3-38             132,096\n",
      "│    └─BasicBlock: 2-8                   --\n",
      "│    │    └─Conv2d: 3-39                 2,359,296\n",
      "│    │    └─BatchNorm2d: 3-40            1,024\n",
      "│    │    └─ReLU: 3-41                   --\n",
      "│    │    └─Conv2d: 3-42                 2,359,296\n",
      "│    │    └─BatchNorm2d: 3-43            1,024\n",
      "├─AdaptiveAvgPool2d: 1-9                 --\n",
      "├─Linear: 1-10                           5,130\n",
      "=================================================================\n",
      "Total params: 11,181,642\n",
      "Trainable params: 11,181,642\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "resnet18_1 = models.resnet18(weights=\"DEFAULT\")\n",
    "\n",
    "# start with random weights\n",
    "resnet18_1.fc = nn.Linear(resnet18_1.fc.in_features, 10)\n",
    "\n",
    "resnet18_1 = resnet18_1.to(device)\n",
    "\n",
    "# print(resnet18_1)\n",
    "# print(resnet18_1.fc.weight.data)\n",
    "print(summary(resnet18_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55da56aa-c924-4285-8557-808ae49954ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5130\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResNet                                   --\n",
      "├─Conv2d: 1-1                            (9,408)\n",
      "├─BatchNorm2d: 1-2                       (128)\n",
      "├─ReLU: 1-3                              --\n",
      "├─MaxPool2d: 1-4                         --\n",
      "├─Sequential: 1-5                        --\n",
      "│    └─BasicBlock: 2-1                   --\n",
      "│    │    └─Conv2d: 3-1                  (36,864)\n",
      "│    │    └─BatchNorm2d: 3-2             (128)\n",
      "│    │    └─ReLU: 3-3                    --\n",
      "│    │    └─Conv2d: 3-4                  (36,864)\n",
      "│    │    └─BatchNorm2d: 3-5             (128)\n",
      "│    └─BasicBlock: 2-2                   --\n",
      "│    │    └─Conv2d: 3-6                  (36,864)\n",
      "│    │    └─BatchNorm2d: 3-7             (128)\n",
      "│    │    └─ReLU: 3-8                    --\n",
      "│    │    └─Conv2d: 3-9                  (36,864)\n",
      "│    │    └─BatchNorm2d: 3-10            (128)\n",
      "├─Sequential: 1-6                        --\n",
      "│    └─BasicBlock: 2-3                   --\n",
      "│    │    └─Conv2d: 3-11                 (73,728)\n",
      "│    │    └─BatchNorm2d: 3-12            (256)\n",
      "│    │    └─ReLU: 3-13                   --\n",
      "│    │    └─Conv2d: 3-14                 (147,456)\n",
      "│    │    └─BatchNorm2d: 3-15            (256)\n",
      "│    │    └─Sequential: 3-16             (8,448)\n",
      "│    └─BasicBlock: 2-4                   --\n",
      "│    │    └─Conv2d: 3-17                 (147,456)\n",
      "│    │    └─BatchNorm2d: 3-18            (256)\n",
      "│    │    └─ReLU: 3-19                   --\n",
      "│    │    └─Conv2d: 3-20                 (147,456)\n",
      "│    │    └─BatchNorm2d: 3-21            (256)\n",
      "├─Sequential: 1-7                        --\n",
      "│    └─BasicBlock: 2-5                   --\n",
      "│    │    └─Conv2d: 3-22                 (294,912)\n",
      "│    │    └─BatchNorm2d: 3-23            (512)\n",
      "│    │    └─ReLU: 3-24                   --\n",
      "│    │    └─Conv2d: 3-25                 (589,824)\n",
      "│    │    └─BatchNorm2d: 3-26            (512)\n",
      "│    │    └─Sequential: 3-27             (33,280)\n",
      "│    └─BasicBlock: 2-6                   --\n",
      "│    │    └─Conv2d: 3-28                 (589,824)\n",
      "│    │    └─BatchNorm2d: 3-29            (512)\n",
      "│    │    └─ReLU: 3-30                   --\n",
      "│    │    └─Conv2d: 3-31                 (589,824)\n",
      "│    │    └─BatchNorm2d: 3-32            (512)\n",
      "├─Sequential: 1-8                        --\n",
      "│    └─BasicBlock: 2-7                   --\n",
      "│    │    └─Conv2d: 3-33                 (1,179,648)\n",
      "│    │    └─BatchNorm2d: 3-34            (1,024)\n",
      "│    │    └─ReLU: 3-35                   --\n",
      "│    │    └─Conv2d: 3-36                 (2,359,296)\n",
      "│    │    └─BatchNorm2d: 3-37            (1,024)\n",
      "│    │    └─Sequential: 3-38             (132,096)\n",
      "│    └─BasicBlock: 2-8                   --\n",
      "│    │    └─Conv2d: 3-39                 (2,359,296)\n",
      "│    │    └─BatchNorm2d: 3-40            (1,024)\n",
      "│    │    └─ReLU: 3-41                   --\n",
      "│    │    └─Conv2d: 3-42                 (2,359,296)\n",
      "│    │    └─BatchNorm2d: 3-43            (1,024)\n",
      "├─AdaptiveAvgPool2d: 1-9                 --\n",
      "├─Linear: 1-10                           5,130\n",
      "=================================================================\n",
      "Total params: 11,181,642\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 11,176,512\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# freeze all layers\n",
    "for param in resnet18_1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# let final layer be trainable, that goes into classification head\n",
    "resnet18_1.fc.weight.requires_grad = True\n",
    "resnet18_1.fc.bias.requires_grad = True\n",
    "\n",
    "print(count_trainable_parameters(resnet18_1))\n",
    "print(summary(resnet18_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548275a1-cc10-42f5-84de-f208d276e395",
   "metadata": {},
   "source": [
    "### Train with `batch_size=64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb84558d-7a77-49a4-b73e-0f20cc6c9860",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Learning rate: 0.010000\n",
      "Training - Loss: 1.8961, Accuracy: 0.32, Runtime: 8.57\n",
      "Test - Loss: 1.7694, Accuracy: 0.38\n",
      "Epoch: 2, Learning rate: 0.010000\n",
      "Training - Loss: 1.7298, Accuracy: 0.39, Runtime: 8.17\n",
      "Test - Loss: 1.7118, Accuracy: 0.40\n",
      "Epoch: 3, Learning rate: 0.010000\n",
      "Training - Loss: 1.7199, Accuracy: 0.40, Runtime: 8.18\n",
      "Test - Loss: 1.6913, Accuracy: 0.41\n",
      "Epoch: 4, Learning rate: 0.010000\n",
      "Training - Loss: 1.7070, Accuracy: 0.40, Runtime: 8.29\n",
      "Test - Loss: 1.6642, Accuracy: 0.42\n",
      "Epoch: 5, Learning rate: 0.010000\n",
      "Training - Loss: 1.6889, Accuracy: 0.41, Runtime: 8.17\n",
      "Test - Loss: 1.6822, Accuracy: 0.42\n",
      "Epoch: 6, Learning rate: 0.010000\n",
      "Training - Loss: 1.6868, Accuracy: 0.41, Runtime: 8.16\n",
      "Test - Loss: 1.6863, Accuracy: 0.41\n",
      "Epoch: 7, Learning rate: 0.010000\n",
      "Training - Loss: 1.6910, Accuracy: 0.41, Runtime: 8.23\n",
      "Test - Loss: 1.6602, Accuracy: 0.42\n",
      "Epoch: 8, Learning rate: 0.010000\n",
      "Training - Loss: 1.6825, Accuracy: 0.41, Runtime: 8.19\n",
      "Test - Loss: 1.6524, Accuracy: 0.43\n",
      "Epoch: 9, Learning rate: 0.010000\n",
      "Training - Loss: 1.6923, Accuracy: 0.40, Runtime: 8.05\n",
      "Test - Loss: 1.6652, Accuracy: 0.42\n",
      "Epoch: 10, Learning rate: 0.010000\n",
      "Training - Loss: 1.6833, Accuracy: 0.41, Runtime: 8.18\n",
      "Test - Loss: 1.6534, Accuracy: 0.42\n",
      "Done! - Runtime: 139.90 seconds\n",
      "=========\n",
      "Accuracy for class: plane is 49.5 %\n",
      "Accuracy for class: car   is 39.7 %\n",
      "Accuracy for class: bird  is 30.8 %\n",
      "Accuracy for class: cat   is 27.1 %\n",
      "Accuracy for class: deer  is 51.6 %\n",
      "Accuracy for class: dog   is 35.2 %\n",
      "Accuracy for class: frog  is 56.9 %\n",
      "Accuracy for class: horse is 35.6 %\n",
      "Accuracy for class: ship  is 49.7 %\n",
      "Accuracy for class: truck is 43.7 %\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "resnet18_1_dict = dict(model=resnet18_1, criterion=criterion, device=device, lr=0.01, momentum=0.,\n",
    "                       max_epochs=max_epochs, do_test=True)\n",
    "\n",
    "stats = train_loop(trainloader, valloader, **resnet18_1_dict)\n",
    "\n",
    "print(\"=========\")\n",
    "test_class(resnet18_1, device, criterion, valloader, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeea4a06-7c89-4255-8554-01b314d3c149",
   "metadata": {},
   "source": [
    "### Train with `batch_size=128`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b6551d6-a363-46c4-a289-cd19216bb8e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Learning rate: 0.010000\n",
      "Training - Loss: 1.8610, Accuracy: 0.35, Runtime: 8.25\n",
      "Test - Loss: 1.7563, Accuracy: 0.39\n",
      "Epoch: 2, Learning rate: 0.010000\n",
      "Training - Loss: 1.7389, Accuracy: 0.39, Runtime: 8.02\n",
      "Test - Loss: 1.7122, Accuracy: 0.41\n",
      "Epoch: 3, Learning rate: 0.010000\n",
      "Training - Loss: 1.7203, Accuracy: 0.40, Runtime: 7.95\n",
      "Test - Loss: 1.7240, Accuracy: 0.40\n",
      "Epoch: 4, Learning rate: 0.010000\n",
      "Training - Loss: 1.7270, Accuracy: 0.40, Runtime: 7.96\n",
      "Test - Loss: 1.6928, Accuracy: 0.42\n",
      "Epoch: 5, Learning rate: 0.010000\n",
      "Training - Loss: 1.7161, Accuracy: 0.41, Runtime: 7.93\n",
      "Test - Loss: 1.7467, Accuracy: 0.40\n",
      "Epoch: 6, Learning rate: 0.010000\n",
      "Training - Loss: 1.7112, Accuracy: 0.40, Runtime: 7.92\n",
      "Test - Loss: 1.8087, Accuracy: 0.38\n",
      "Epoch: 7, Learning rate: 0.010000\n",
      "Training - Loss: 1.7245, Accuracy: 0.40, Runtime: 7.93\n",
      "Test - Loss: 1.7509, Accuracy: 0.39\n",
      "Epoch: 8, Learning rate: 0.010000\n",
      "Training - Loss: 1.7102, Accuracy: 0.40, Runtime: 7.88\n",
      "Test - Loss: 1.7310, Accuracy: 0.40\n",
      "Epoch: 9, Learning rate: 0.010000\n",
      "Training - Loss: 1.7175, Accuracy: 0.40, Runtime: 7.97\n",
      "Test - Loss: 1.7440, Accuracy: 0.40\n",
      "Epoch: 10, Learning rate: 0.010000\n",
      "Training - Loss: 1.7065, Accuracy: 0.41, Runtime: 7.95\n",
      "Test - Loss: 1.7146, Accuracy: 0.40\n",
      "Epoch: 11, Learning rate: 0.010000\n",
      "Training - Loss: 1.7117, Accuracy: 0.40, Runtime: 8.13\n",
      "Test - Loss: 1.7399, Accuracy: 0.40\n",
      "Epoch: 12, Learning rate: 0.010000\n",
      "Training - Loss: 1.7092, Accuracy: 0.41, Runtime: 8.30\n",
      "Test - Loss: 1.7183, Accuracy: 0.40\n",
      "Epoch: 13, Learning rate: 0.010000\n",
      "Training - Loss: 1.7045, Accuracy: 0.41, Runtime: 8.03\n",
      "Test - Loss: 1.6912, Accuracy: 0.41\n",
      "Epoch: 14, Learning rate: 0.010000\n",
      "Training - Loss: 1.7151, Accuracy: 0.40, Runtime: 8.28\n",
      "Test - Loss: 1.7293, Accuracy: 0.40\n",
      "Epoch: 15, Learning rate: 0.010000\n",
      "Training - Loss: 1.7147, Accuracy: 0.41, Runtime: 7.98\n",
      "Test - Loss: 1.6853, Accuracy: 0.41\n",
      "Epoch: 16, Learning rate: 0.010000\n",
      "Training - Loss: 1.7116, Accuracy: 0.40, Runtime: 8.19\n",
      "Test - Loss: 1.6912, Accuracy: 0.42\n",
      "Epoch: 17, Learning rate: 0.010000\n",
      "Training - Loss: 1.7068, Accuracy: 0.41, Runtime: 8.14\n",
      "Test - Loss: 1.7141, Accuracy: 0.41\n",
      "Epoch: 18, Learning rate: 0.010000\n",
      "Training - Loss: 1.7179, Accuracy: 0.40, Runtime: 8.09\n",
      "Test - Loss: 1.7196, Accuracy: 0.40\n",
      "Epoch: 19, Learning rate: 0.010000\n",
      "Training - Loss: 1.7059, Accuracy: 0.41, Runtime: 8.09\n",
      "Test - Loss: 1.7021, Accuracy: 0.41\n",
      "Epoch: 20, Learning rate: 0.010000\n",
      "Training - Loss: 1.7152, Accuracy: 0.41, Runtime: 8.33\n",
      "Test - Loss: 1.7229, Accuracy: 0.40\n",
      "Done! - Runtime: 275.65 seconds\n",
      "=========\n",
      "Accuracy for class: plane is 56.3 %\n",
      "Accuracy for class: car   is 43.3 %\n",
      "Accuracy for class: bird  is 12.7 %\n",
      "Accuracy for class: cat   is 27.3 %\n",
      "Accuracy for class: deer  is 24.4 %\n",
      "Accuracy for class: dog   is 29.3 %\n",
      "Accuracy for class: frog  is 68.8 %\n",
      "Accuracy for class: horse is 44.8 %\n",
      "Accuracy for class: ship  is 50.0 %\n",
      "Accuracy for class: truck is 43.8 %\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "resnet18_1_dict = dict(model=resnet18_1, criterion=criterion, device=device, lr=0.01, momentum=0.9,\n",
    "                       max_epochs=max_epochs, do_test=True)\n",
    "\n",
    "stats = train_loop(trainloader, valloader, **resnet18_1_dict)\n",
    "\n",
    "print(\"=========\")\n",
    "test_class(resnet18_1, device, criterion, valloader, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb199161-d511-47f7-b0fe-c30af275ab5c",
   "metadata": {},
   "source": [
    "## Classification head: MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f7f25e7-a6e7-4e06-8d1d-12f2ba11d3cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet18_2 = models.resnet18(weights=\"DEFAULT\")\n",
    "resnet18_2.fc = nn.Sequential(\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)  # logits\n",
    ")\n",
    "resnet18_2 = resnet18_2.to(device)\n",
    "print(resnet18_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97bcac5d-e84b-4805-9c9b-4223d28b9c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165514"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(512*256 + 256) + (256*128 + 128) + (128*10 + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63e4d7ab-6195-4a91-894d-c4d0c714ef69",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165514\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResNet                                   --\n",
      "├─Conv2d: 1-1                            (9,408)\n",
      "├─BatchNorm2d: 1-2                       (128)\n",
      "├─ReLU: 1-3                              --\n",
      "├─MaxPool2d: 1-4                         --\n",
      "├─Sequential: 1-5                        --\n",
      "│    └─BasicBlock: 2-1                   --\n",
      "│    │    └─Conv2d: 3-1                  (36,864)\n",
      "│    │    └─BatchNorm2d: 3-2             (128)\n",
      "│    │    └─ReLU: 3-3                    --\n",
      "│    │    └─Conv2d: 3-4                  (36,864)\n",
      "│    │    └─BatchNorm2d: 3-5             (128)\n",
      "│    └─BasicBlock: 2-2                   --\n",
      "│    │    └─Conv2d: 3-6                  (36,864)\n",
      "│    │    └─BatchNorm2d: 3-7             (128)\n",
      "│    │    └─ReLU: 3-8                    --\n",
      "│    │    └─Conv2d: 3-9                  (36,864)\n",
      "│    │    └─BatchNorm2d: 3-10            (128)\n",
      "├─Sequential: 1-6                        --\n",
      "│    └─BasicBlock: 2-3                   --\n",
      "│    │    └─Conv2d: 3-11                 (73,728)\n",
      "│    │    └─BatchNorm2d: 3-12            (256)\n",
      "│    │    └─ReLU: 3-13                   --\n",
      "│    │    └─Conv2d: 3-14                 (147,456)\n",
      "│    │    └─BatchNorm2d: 3-15            (256)\n",
      "│    │    └─Sequential: 3-16             (8,448)\n",
      "│    └─BasicBlock: 2-4                   --\n",
      "│    │    └─Conv2d: 3-17                 (147,456)\n",
      "│    │    └─BatchNorm2d: 3-18            (256)\n",
      "│    │    └─ReLU: 3-19                   --\n",
      "│    │    └─Conv2d: 3-20                 (147,456)\n",
      "│    │    └─BatchNorm2d: 3-21            (256)\n",
      "├─Sequential: 1-7                        --\n",
      "│    └─BasicBlock: 2-5                   --\n",
      "│    │    └─Conv2d: 3-22                 (294,912)\n",
      "│    │    └─BatchNorm2d: 3-23            (512)\n",
      "│    │    └─ReLU: 3-24                   --\n",
      "│    │    └─Conv2d: 3-25                 (589,824)\n",
      "│    │    └─BatchNorm2d: 3-26            (512)\n",
      "│    │    └─Sequential: 3-27             (33,280)\n",
      "│    └─BasicBlock: 2-6                   --\n",
      "│    │    └─Conv2d: 3-28                 (589,824)\n",
      "│    │    └─BatchNorm2d: 3-29            (512)\n",
      "│    │    └─ReLU: 3-30                   --\n",
      "│    │    └─Conv2d: 3-31                 (589,824)\n",
      "│    │    └─BatchNorm2d: 3-32            (512)\n",
      "├─Sequential: 1-8                        --\n",
      "│    └─BasicBlock: 2-7                   --\n",
      "│    │    └─Conv2d: 3-33                 (1,179,648)\n",
      "│    │    └─BatchNorm2d: 3-34            (1,024)\n",
      "│    │    └─ReLU: 3-35                   --\n",
      "│    │    └─Conv2d: 3-36                 (2,359,296)\n",
      "│    │    └─BatchNorm2d: 3-37            (1,024)\n",
      "│    │    └─Sequential: 3-38             (132,096)\n",
      "│    └─BasicBlock: 2-8                   --\n",
      "│    │    └─Conv2d: 3-39                 (2,359,296)\n",
      "│    │    └─BatchNorm2d: 3-40            (1,024)\n",
      "│    │    └─ReLU: 3-41                   --\n",
      "│    │    └─Conv2d: 3-42                 (2,359,296)\n",
      "│    │    └─BatchNorm2d: 3-43            (1,024)\n",
      "├─AdaptiveAvgPool2d: 1-9                 --\n",
      "├─Sequential: 1-10                       --\n",
      "│    └─Linear: 2-9                       131,328\n",
      "│    └─ReLU: 2-10                        --\n",
      "│    └─Linear: 2-11                      32,896\n",
      "│    └─ReLU: 2-12                        --\n",
      "│    └─Linear: 2-13                      1,290\n",
      "=================================================================\n",
      "Total params: 11,342,026\n",
      "Trainable params: 165,514\n",
      "Non-trainable params: 11,176,512\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# freeze all layers\n",
    "for param in resnet18_2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# let final layer be trainable, that goes into classification head\n",
    "# random initialization\n",
    "for layer_idx in (0, 2, 4):\n",
    "    resnet18_2.fc[layer_idx].weight.requires_grad = True\n",
    "    resnet18_2.fc[layer_idx].bias.requires_grad = True\n",
    "# resnet18_2.fc.weight.requires_grad = True\n",
    "# resnet18_2.fc.bias.requires_grad = True\n",
    "print(count_trainable_parameters(resnet18_2))\n",
    "print(summary(resnet18_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96a6aa-df10-4783-ad6e-dfac1004fc86",
   "metadata": {},
   "source": [
    "### Training with `batch_size=64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "915fa93f-998d-456d-8f7d-b49a55e45be1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Learning rate: 0.010000\n",
      "Training - Loss: 1.8652, Accuracy: 0.33, Runtime: 8.43\n",
      "Test - Loss: 1.7251, Accuracy: 0.39\n",
      "Epoch: 2, Learning rate: 0.010000\n",
      "Training - Loss: 1.7355, Accuracy: 0.38, Runtime: 8.12\n",
      "Test - Loss: 1.7407, Accuracy: 0.38\n",
      "Epoch: 3, Learning rate: 0.010000\n",
      "Training - Loss: 1.7252, Accuracy: 0.39, Runtime: 8.38\n",
      "Test - Loss: 1.7009, Accuracy: 0.39\n",
      "Epoch: 4, Learning rate: 0.010000\n",
      "Training - Loss: 1.7179, Accuracy: 0.39, Runtime: 8.02\n",
      "Test - Loss: 1.6821, Accuracy: 0.40\n",
      "Epoch: 5, Learning rate: 0.010000\n",
      "Training - Loss: 1.7161, Accuracy: 0.39, Runtime: 8.77\n",
      "Test - Loss: 1.6914, Accuracy: 0.40\n",
      "Epoch: 6, Learning rate: 0.010000\n",
      "Training - Loss: 1.7121, Accuracy: 0.39, Runtime: 8.54\n",
      "Test - Loss: 1.7317, Accuracy: 0.39\n",
      "Epoch: 7, Learning rate: 0.010000\n",
      "Training - Loss: 1.7172, Accuracy: 0.39, Runtime: 8.48\n",
      "Test - Loss: 1.7116, Accuracy: 0.40\n",
      "Epoch: 8, Learning rate: 0.010000\n",
      "Training - Loss: 1.7098, Accuracy: 0.39, Runtime: 8.40\n",
      "Test - Loss: 1.6876, Accuracy: 0.39\n",
      "Epoch: 9, Learning rate: 0.010000\n",
      "Training - Loss: 1.7034, Accuracy: 0.39, Runtime: 8.39\n",
      "Test - Loss: 1.6900, Accuracy: 0.40\n",
      "Epoch: 10, Learning rate: 0.010000\n",
      "Training - Loss: 1.7067, Accuracy: 0.39, Runtime: 8.31\n",
      "Test - Loss: 1.6598, Accuracy: 0.41\n",
      "Done! - Runtime: 142.87 seconds\n",
      "=========\n",
      "Accuracy for class: plane is 46.2 %\n",
      "Accuracy for class: car   is 39.0 %\n",
      "Accuracy for class: bird  is 34.1 %\n",
      "Accuracy for class: cat   is 40.0 %\n",
      "Accuracy for class: deer  is 36.5 %\n",
      "Accuracy for class: dog   is 31.9 %\n",
      "Accuracy for class: frog  is 56.4 %\n",
      "Accuracy for class: horse is 38.3 %\n",
      "Accuracy for class: ship  is 52.5 %\n",
      "Accuracy for class: truck is 43.4 %\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "resnet18_2_dict = dict(model=resnet18_2, criterion=criterion, device=device, lr=0.01, momentum=0.9,\n",
    "                       max_epochs=max_epochs, do_test=True)\n",
    "\n",
    "stats = train_loop(trainloader, valloader, **resnet18_2_dict)\n",
    "\n",
    "print(\"=========\")\n",
    "test_class(resnet18_2, device, criterion, valloader, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830d70ff-2f87-4f17-aab8-a15f7d0d677c",
   "metadata": {},
   "source": [
    "### Training with `batch_size=128`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3a9c235-29f8-4cba-93a7-1b3c2da72fb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Learning rate: 0.010000\n",
      "Training - Loss: 1.6623, Accuracy: 0.41, Runtime: 8.18\n",
      "Test - Loss: 1.6614, Accuracy: 0.42\n",
      "Epoch: 2, Learning rate: 0.010000\n",
      "Training - Loss: 1.6558, Accuracy: 0.41, Runtime: 8.19\n",
      "Test - Loss: 1.6517, Accuracy: 0.42\n",
      "Epoch: 3, Learning rate: 0.010000\n",
      "Training - Loss: 1.6553, Accuracy: 0.41, Runtime: 8.21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      3\u001b[0m resnet18_2_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(model\u001b[38;5;241m=\u001b[39mresnet18_2, criterion\u001b[38;5;241m=\u001b[39mcriterion, device\u001b[38;5;241m=\u001b[39mdevice, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m,\n\u001b[0;32m      4\u001b[0m                        max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs, do_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 6\u001b[0m stats \u001b[38;5;241m=\u001b[39m train_loop(trainloader, valloader, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresnet18_2_dict)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=========\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m test_class(resnet18_2, device, criterion, valloader, classes)\n",
      "Cell \u001b[1;32mIn[6], line 22\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(train_loader, test_loader, model, criterion, device, lr, momentum, max_epochs, do_test)\u001b[0m\n\u001b[0;32m     19\u001b[0m accs_train\u001b[38;5;241m.\u001b[39mappend(acc_train)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_test:\n\u001b[1;32m---> 22\u001b[0m     loss_test, acc_test \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     losses_test\u001b[38;5;241m.\u001b[39mappend(loss_test)\n\u001b[0;32m     24\u001b[0m     accs_test\u001b[38;5;241m.\u001b[39mappend(acc_test)\n",
      "File \u001b[1;32m~\\Documents\\Python Projects\\Comp-Viz\\Lab1\\lab1_utils.py:59\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(model, device, criterion, test_loader)\u001b[0m\n\u001b[0;32m     56\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m     60\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;66;03m## Compute loss\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-cuda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:440\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-cuda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-cuda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1038\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1031\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1038\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-cuda\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-cuda\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-cuda\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-cuda\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-cuda\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "resnet18_2_dict = dict(model=resnet18_2, criterion=criterion, device=device, lr=0.01, momentum=0.9,\n",
    "                       max_epochs=max_epochs, do_test=True)\n",
    "\n",
    "stats = train_loop(trainloader, valloader, **resnet18_2_dict)\n",
    "\n",
    "print(\"=========\")\n",
    "test_class(resnet18_2, device, criterion, valloader, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9fe908-d434-4d90-b29a-e9f4179f309f",
   "metadata": {},
   "source": [
    "## Classification head + previous layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7655eecd-807e-42ee-af21-ffa2493b3a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94050735-6b84-495d-8a9a-0e0a9de6a508",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Cambiare il learning rate dei layer finali oppure mettere trainable un layer di convoluzione interno e cambiargli learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79767d7-1fc8-47fa-a118-baa73f86d74d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63f3b136-feab-40b5-a1f5-e6aa10e6f8ac",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Model selection strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40eed69-e774-4e0b-9559-e8d71207fad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
