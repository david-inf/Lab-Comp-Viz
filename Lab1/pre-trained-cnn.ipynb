{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da617566-e649-4687-99f4-f1d5e224fc9c",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ac5a46-42fb-4a45-88f7-99fc77312f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchinfo import summary\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0719e4de-99a9-4854-bde7-e3c3ee9305c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab1_utils import train_loop_sched, count_trainable_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31e732e0-7fd0-4c6f-b361-6d658780b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab1_utils import train, test, get_lr\n",
    "from lab1_utils import multiple_diagnostic, test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1bf375e-5a56-4c44-8f23-f5778b61e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "batch_size = 64\n",
    "# batch_size = 128\n",
    "max_epochs = 6\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0817ce9e-ba04-4a23-8944-be73d88663ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # some augmentation\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    transforms.Resize(224)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    transforms.Resize(224)  # anche per il test??\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "# create a split for train/validation. We can use early stop\n",
    "trainset, valset = torch.utils.data.random_split(dataset, [40000, 10000])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2,\n",
    "                                          drop_last=True, pin_memory=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                        shuffle=False, num_workers=2,\n",
    "                                        drop_last=False, pin_memory=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2,\n",
    "                                         drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f03c2-0ee3-48d0-bb6a-7f97ca7cecc1",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Scegliamo di usare `resnet18`\n",
    "\n",
    "Due prove di fine-tuning:\n",
    "- Modificare il layer finale di classificazione `resnet18_1` partendo dai pesi originali cercando di arrivare alle migliori performance possibili\n",
    "- Mettere in coda un MLP `resnet18_2`\n",
    "- Riaddestrare un layer precedente `resnet18_3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8628ef8-6ddc-43f3-b755-8c54c1a848d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_loss_acc = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed0b63-24e2-4efc-89d5-d06c9c25ecad",
   "metadata": {},
   "source": [
    "## Classification head: linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93750a13-ef9f-4bb3-aaf2-5a0d59fa9d72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Init model\n",
    "resnet18_1 = models.resnet18(weights=\"DEFAULT\")\n",
    "\n",
    "## Random init weights for classification head\n",
    "resnet18_1.fc = nn.Linear(resnet18_1.fc.in_features, 10)\n",
    "\n",
    "## Default init weights for classification head\n",
    "im_weights = resnet18_1.fc.weight[:10]\n",
    "resnet18_1.fc.weight.data = im_weights.data\n",
    "\n",
    "## Send model to `device`\n",
    "resnet18_1 = resnet18_1.to(device)\n",
    "\n",
    "# print(resnet18_1)\n",
    "# print(resnet18_1.fc.weight.data)\n",
    "# print(summary(resnet18_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55da56aa-c924-4285-8557-808ae49954ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "## Freeze all layers\n",
    "for param in resnet18_1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "## let final layer be trainable, that goes into classification head\n",
    "resnet18_1.fc.weight.requires_grad = True\n",
    "resnet18_1.fc.bias.requires_grad = True\n",
    "\n",
    "print(f\"Trainable parameters: {count_trainable_parameters(resnet18_1)}\")\n",
    "# print(summary(resnet18_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d6f6e6-4555-404e-b0ad-dfaa8edadfa8",
   "metadata": {},
   "source": [
    "Train linear classification head with SGD using exponential scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b6551d6-a363-46c4-a289-cd19216bb8e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Learning rate: 0.100000\n",
      "Training - Loss: 4.0132, Accuracy: 0.66, Runtime: 48.08\n",
      "Test - Loss: 3.6889, Accuracy: 0.68\n",
      "Epoch: 2, Learning rate: 0.080000\n",
      "Training - Loss: 2.3707, Accuracy: 0.70, Runtime: 48.53\n",
      "Test - Loss: 2.5345, Accuracy: 0.68\n",
      "Epoch: 3, Learning rate: 0.064000\n",
      "Training - Loss: 1.9399, Accuracy: 0.72, Runtime: 48.47\n",
      "Test - Loss: 1.9044, Accuracy: 0.71\n",
      "Epoch: 4, Learning rate: 0.051200\n",
      "Training - Loss: 1.6157, Accuracy: 0.72, Runtime: 48.55\n",
      "Test - Loss: 1.7710, Accuracy: 0.70\n",
      "Epoch: 5, Learning rate: 0.040960\n",
      "Training - Loss: 1.3378, Accuracy: 0.74, Runtime: 48.59\n",
      "Test - Loss: 1.7165, Accuracy: 0.67\n",
      "Epoch: 6, Learning rate: 0.032768\n",
      "Training - Loss: 1.1797, Accuracy: 0.74, Runtime: 48.33\n",
      "Test - Loss: 1.3215, Accuracy: 0.71\n",
      "Done! - Runtime: 384.67 seconds\n",
      "=========\n",
      "Accuracy for class: plane is 60.5 %\n",
      "Accuracy for class: car   is 86.9 %\n",
      "Accuracy for class: bird  is 75.6 %\n",
      "Accuracy for class: cat   is 26.9 %\n",
      "Accuracy for class: deer  is 43.8 %\n",
      "Accuracy for class: dog   is 82.0 %\n",
      "Accuracy for class: frog  is 89.1 %\n",
      "Accuracy for class: horse is 90.9 %\n",
      "Accuracy for class: ship  is 94.7 %\n",
      "Accuracy for class: truck is 67.2 %\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(resnet18_1.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = ExponentialLR(optimizer, 0.8)\n",
    "\n",
    "stats = train_loop_sched(trainloader, valloader, resnet18_1, criterion, device,\n",
    "                         optimizer, scheduler, max_epochs)\n",
    "\n",
    "head_loss_acc[\"Linear\"] = [stats[0], stats[3]]\n",
    "\n",
    "print(\"=========\")\n",
    "test_class(resnet18_1, device, criterion, valloader, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb199161-d511-47f7-b0fe-c30af275ab5c",
   "metadata": {},
   "source": [
    "## Classification head: MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f7f25e7-a6e7-4e06-8d1d-12f2ba11d3cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Init model\n",
    "resnet18_2 = models.resnet18(weights=\"DEFAULT\")\n",
    "\n",
    "## Add MLP\n",
    "resnet18_2.fc = nn.Sequential(\n",
    "    nn.Linear(512, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)  # logits\n",
    ")\n",
    "\n",
    "## Send model to `device`\n",
    "resnet18_2 = resnet18_2.to(device)\n",
    "\n",
    "# print(resnet18_2)\n",
    "# print(summary(resnet18_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63e4d7ab-6195-4a91-894d-c4d0c714ef69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 33482\n"
     ]
    }
   ],
   "source": [
    "## Freeze all layers\n",
    "for param in resnet18_2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "## Let final layer be trainable, that goes into classification head\n",
    "# random initialization\n",
    "for param in resnet18_2.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(f\"Trainable parameters: {count_trainable_parameters(resnet18_2)}\")\n",
    "# print(summary(resnet18_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92ad891-ddde-4b2e-afef-9e5bc4454a1f",
   "metadata": {},
   "source": [
    "Train MLP classification head with SGD using exponential scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3a9c235-29f8-4cba-93a7-1b3c2da72fb8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Learning rate: 0.100000\n",
      "Training - Loss: 1.9092, Accuracy: 0.29, Runtime: 48.89\n",
      "Test - Loss: 2.1788, Accuracy: 0.19\n",
      "Epoch: 2, Learning rate: 0.080000\n",
      "Training - Loss: 1.9047, Accuracy: 0.28, Runtime: 49.13\n",
      "Test - Loss: 1.8783, Accuracy: 0.27\n",
      "Epoch: 3, Learning rate: 0.064000\n",
      "Training - Loss: 1.9014, Accuracy: 0.28, Runtime: 49.22\n",
      "Test - Loss: 1.7281, Accuracy: 0.34\n",
      "Epoch: 4, Learning rate: 0.051200\n",
      "Training - Loss: 1.7695, Accuracy: 0.31, Runtime: 49.22\n",
      "Test - Loss: 1.9628, Accuracy: 0.30\n",
      "Epoch: 5, Learning rate: 0.040960\n",
      "Training - Loss: 1.6589, Accuracy: 0.35, Runtime: 48.86\n",
      "Test - Loss: 1.7467, Accuracy: 0.34\n",
      "Epoch: 6, Learning rate: 0.032768\n",
      "Training - Loss: 1.4766, Accuracy: 0.44, Runtime: 48.28\n",
      "Test - Loss: 1.2134, Accuracy: 0.56\n",
      "Done! - Runtime: 388.05 seconds\n",
      "=========\n",
      "Accuracy for class: plane is 73.7 %\n",
      "Accuracy for class: car   is 65.8 %\n",
      "Accuracy for class: bird  is 46.4 %\n",
      "Accuracy for class: cat   is 48.9 %\n",
      "Accuracy for class: deer  is 52.1 %\n",
      "Accuracy for class: dog   is 71.1 %\n",
      "Accuracy for class: frog  is 44.2 %\n",
      "Accuracy for class: horse is 19.1 %\n",
      "Accuracy for class: ship  is 52.6 %\n",
      "Accuracy for class: truck is 88.8 %\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(resnet18_2.parameters(), lr=0.1, momentum=0.9)\n",
    "scheduler = ExponentialLR(optimizer, 0.8)\n",
    "\n",
    "stats = train_loop_sched(trainloader, valloader, resnet18_2, criterion, device,\n",
    "                         optimizer, scheduler, max_epochs)\n",
    "\n",
    "head_loss_acc[\"MLP\"] = [stats[0], stats[3]]\n",
    "\n",
    "print(\"=========\")\n",
    "test_class(resnet18_2, device, criterion, valloader, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9fe908-d434-4d90-b29a-e9f4179f309f",
   "metadata": {},
   "source": [
    "## Classification head + previous layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7655eecd-807e-42ee-af21-ffa2493b3a90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Init model\n",
    "resnet18_1 = models.resnet18(weights=\"DEFAULT\")\n",
    "\n",
    "## Random init weights for classification head\n",
    "resnet18_1.fc = nn.Linear(resnet18_1.fc.in_features, 10)\n",
    "## Default init weights for classification head\n",
    "im_weights = resnet18_1.fc.weight[:10]\n",
    "resnet18_1.fc.weight.data = im_weights.data\n",
    "\n",
    "## Send model to `device`\n",
    "resnet18_1 = resnet18_1.to(device)\n",
    "\n",
    "# print(resnet18_1)\n",
    "# print(resnet18_1.fc.weight.data)\n",
    "# print(summary(resnet18_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73bf6a30-963a-48e1-b2eb-a4a27de3c073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 8393728\n"
     ]
    }
   ],
   "source": [
    "## Freeze all layers\n",
    "for param in resnet18_1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "## let final layer be trainable, that goes into classification head\n",
    "resnet18_1.fc.requires_grad = True\n",
    "\n",
    "## Let also one previous layer to be trainable\n",
    "for param in resnet18_1.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(f\"Trainable parameters: {count_trainable_parameters(resnet18_1)}\")\n",
    "# print(summary(resnet18_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783f3db1-9cb7-4db1-8aea-bcc3df4e3032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94050735-6b84-495d-8a9a-0e0a9de6a508",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Cambiare il learning rate dei layer finali oppure mettere trainable un layer di convoluzione interno e cambiargli learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79767d7-1fc8-47fa-a118-baa73f86d74d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63f3b136-feab-40b5-a1f5-e6aa10e6f8ac",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Model selection strategy??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40eed69-e774-4e0b-9559-e8d71207fad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
