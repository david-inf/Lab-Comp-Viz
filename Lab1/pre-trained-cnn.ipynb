{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da617566-e649-4687-99f4-f1d5e224fc9c",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ac5a46-42fb-4a45-88f7-99fc77312f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchinfo import summary\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e732e0-7fd0-4c6f-b361-6d658780b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "from lab1_utils import train_loop, train, test, get_lr\n",
    "from lab1_utils import multiple_diagnostic, test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "063715bf-fcc8-40e7-9d58-4380ab92245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0817ce9e-ba04-4a23-8944-be73d88663ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # some augmentation\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "# create a split for train/validation. We can use early stop\n",
    "trainset, valset = torch.utils.data.random_split(dataset, [40000, 10000])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2,\n",
    "                                          drop_last=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2,\n",
    "                                          drop_last=False)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2,\n",
    "                                          drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1bf375e-5a56-4c44-8f23-f5778b61e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "lr = 0.01\n",
    "max_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f03c2-0ee3-48d0-bb6a-7f97ca7cecc1",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Scegliamo di usare `resnet18`\n",
    "\n",
    "Due prove di fine-tuning:\n",
    "- Modificare il layer finale di classificazione `resnet18_1` partendo dai pesi originali\n",
    "- Mettere in coda un MLP `resnet18_2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed0b63-24e2-4efc-89d5-d06c9c25ecad",
   "metadata": {},
   "source": [
    "### Classifier layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93750a13-ef9f-4bb3-aaf2-5a0d59fa9d72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet18_1 = models.resnet18(weights=\"DEFAULT\")\n",
    "\n",
    "# start with random weights\n",
    "resnet18_1.fc = nn.Linear(resnet18_1.fc.in_features, 10)\n",
    "\n",
    "# start with resnet18 classifier weights\n",
    "# im_weights = resnet18_1.fc.weight[:10]\n",
    "# resnet18_1.fc = nn.Linear(resnet18_1.fc.in_features, 10)\n",
    "# resnet18_1.fc.weight.data = im_weights.data\n",
    "\n",
    "resnet18_1 = resnet18_1.to(device)\n",
    "\n",
    "# print(resnet18_1)\n",
    "# print(resnet18_1.fc.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55da56aa-c924-4285-8557-808ae49954ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5130"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freeze all layers\n",
    "for param in resnet18_1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# let final layer be trainable, that goes into classification head\n",
    "resnet18_1.fc.weight.requires_grad = True\n",
    "resnet18_1.fc.bias.requires_grad = True\n",
    "count_trainable_parameters(resnet18_1)\n",
    "# print(summary(resnet18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb84558d-7a77-49a4-b73e-0f20cc6c9860",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Learning rate: 0.001000\n",
      "Training - Loss: 2.5263, Accuracy: 0.26, Runtime: 11.23\n",
      "Test - Loss: 1.9734, Accuracy: 0.35\n",
      "Epoch: 2, Learning rate: 0.001000\n",
      "Training - Loss: 1.8313, Accuracy: 0.37, Runtime: 10.94\n",
      "Test - Loss: 1.7972, Accuracy: 0.38\n",
      "Epoch: 3, Learning rate: 0.001000\n",
      "Training - Loss: 1.7486, Accuracy: 0.39, Runtime: 11.21\n",
      "Test - Loss: 1.7323, Accuracy: 0.40\n",
      "Epoch: 4, Learning rate: 0.001000\n",
      "Training - Loss: 1.7052, Accuracy: 0.40, Runtime: 11.31\n",
      "Test - Loss: 1.7274, Accuracy: 0.39\n",
      "Epoch: 5, Learning rate: 0.001000\n",
      "Training - Loss: 1.6992, Accuracy: 0.40, Runtime: 11.27\n",
      "Test - Loss: 1.7056, Accuracy: 0.41\n",
      "Epoch: 6, Learning rate: 0.001000\n",
      "Training - Loss: 1.6820, Accuracy: 0.41, Runtime: 11.34\n",
      "Test - Loss: 1.7170, Accuracy: 0.40\n",
      "Epoch: 7, Learning rate: 0.001000\n",
      "Training - Loss: 1.6842, Accuracy: 0.41, Runtime: 11.28\n",
      "Test - Loss: 1.7165, Accuracy: 0.40\n",
      "Epoch: 8, Learning rate: 0.001000\n",
      "Training - Loss: 1.6737, Accuracy: 0.41, Runtime: 11.76\n",
      "Test - Loss: 1.6782, Accuracy: 0.42\n",
      "Epoch: 9, Learning rate: 0.001000\n",
      "Training - Loss: 1.6762, Accuracy: 0.41, Runtime: 10.95\n",
      "Test - Loss: 1.6887, Accuracy: 0.41\n",
      "Epoch: 10, Learning rate: 0.001000\n",
      "Training - Loss: 1.6806, Accuracy: 0.41, Runtime: 11.22\n",
      "Test - Loss: 1.6857, Accuracy: 0.42\n",
      "Done! - Runtime: 184.12 seconds\n",
      "=========\n",
      "Accuracy for class: plane is 38.7 %\n",
      "Accuracy for class: car   is 36.5 %\n",
      "Accuracy for class: bird  is 27.5 %\n",
      "Accuracy for class: cat   is 22.2 %\n",
      "Accuracy for class: deer  is 42.7 %\n",
      "Accuracy for class: dog   is 47.9 %\n",
      "Accuracy for class: frog  is 54.2 %\n",
      "Accuracy for class: horse is 40.8 %\n",
      "Accuracy for class: ship  is 63.4 %\n",
      "Accuracy for class: truck is 46.8 %\n"
     ]
    }
   ],
   "source": [
    "# start with resnet18 classifier's weights\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "resnet18_1_dict = dict(model=resnet18_1, criterion=criterion, device=device, lr=0.001, momentum=0.9,\n",
    "                       max_epochs=max_epochs, do_test=True)\n",
    "\n",
    "stats = train_loop(trainloader, valloader, **resnet18_1_dict)\n",
    "\n",
    "print(\"=========\")\n",
    "test_class(resnet18_1, device, criterion, valloader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7c121cd-6f8a-49e4-9ad1-db3c08189563",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Learning rate: 0.001000\n",
      "Training - Loss: 1.8957, Accuracy: 0.33, Runtime: 10.94\n",
      "Test - Loss: 1.7687, Accuracy: 0.39\n",
      "Epoch: 2, Learning rate: 0.001000\n",
      "Training - Loss: 1.7259, Accuracy: 0.40, Runtime: 10.95\n",
      "Test - Loss: 1.7212, Accuracy: 0.41\n",
      "Epoch: 3, Learning rate: 0.001000\n",
      "Training - Loss: 1.6999, Accuracy: 0.40, Runtime: 10.86\n",
      "Test - Loss: 1.7111, Accuracy: 0.40\n",
      "Epoch: 4, Learning rate: 0.001000\n",
      "Training - Loss: 1.6926, Accuracy: 0.41, Runtime: 10.84\n",
      "Test - Loss: 1.6973, Accuracy: 0.41\n",
      "Epoch: 5, Learning rate: 0.001000\n",
      "Training - Loss: 1.6823, Accuracy: 0.41, Runtime: 10.91\n",
      "Test - Loss: 1.7063, Accuracy: 0.41\n",
      "Epoch: 6, Learning rate: 0.001000\n",
      "Training - Loss: 1.6845, Accuracy: 0.41, Runtime: 11.31\n",
      "Test - Loss: 1.6755, Accuracy: 0.42\n",
      "Epoch: 7, Learning rate: 0.001000\n",
      "Training - Loss: 1.6744, Accuracy: 0.41, Runtime: 11.30\n",
      "Test - Loss: 1.6951, Accuracy: 0.41\n",
      "Epoch: 8, Learning rate: 0.001000\n",
      "Training - Loss: 1.6719, Accuracy: 0.41, Runtime: 11.34\n",
      "Test - Loss: 1.6940, Accuracy: 0.41\n",
      "Epoch: 9, Learning rate: 0.001000\n",
      "Training - Loss: 1.6774, Accuracy: 0.41, Runtime: 10.94\n",
      "Test - Loss: 1.6773, Accuracy: 0.41\n",
      "Epoch: 10, Learning rate: 0.001000\n",
      "Training - Loss: 1.6734, Accuracy: 0.42, Runtime: 11.31\n",
      "Test - Loss: 1.6792, Accuracy: 0.42\n",
      "Done! - Runtime: 182.78 seconds\n",
      "=========\n",
      "Accuracy for class: plane is 42.2 %\n",
      "Accuracy for class: car   is 58.7 %\n",
      "Accuracy for class: bird  is 35.1 %\n",
      "Accuracy for class: cat   is 37.9 %\n",
      "Accuracy for class: deer  is 45.5 %\n",
      "Accuracy for class: dog   is 29.9 %\n",
      "Accuracy for class: frog  is 45.1 %\n",
      "Accuracy for class: horse is 42.0 %\n",
      "Accuracy for class: ship  is 49.8 %\n",
      "Accuracy for class: truck is 28.4 %\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "resnet18_1_dict = dict(model=resnet18_1, criterion=criterion, device=device, lr=0.001, momentum=0.9,\n",
    "                       max_epochs=max_epochs, do_test=True)\n",
    "\n",
    "stats = train_loop(trainloader, valloader, **resnet18_1_dict)\n",
    "\n",
    "print(\"=========\")\n",
    "test_class(resnet18_1, device, criterion, valloader, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb199161-d511-47f7-b0fe-c30af275ab5c",
   "metadata": {},
   "source": [
    "### Add MLP in head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f7f25e7-a6e7-4e06-8d1d-12f2ba11d3cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet18_2 = models.resnet18(weights=\"DEFAULT\")\n",
    "resnet18_2.fc = nn.Sequential(\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)  # logits\n",
    ")\n",
    "resnet18_2 = resnet18_2.to(device)\n",
    "print(resnet18_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97bcac5d-e84b-4805-9c9b-4223d28b9c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165514"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(512*256 + 256) + (256*128 + 128) + (128*10 + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63e4d7ab-6195-4a91-894d-c4d0c714ef69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165514"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freeze all layers\n",
    "for param in resnet18_2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# let final layer be trainable, that goes into classification head\n",
    "# random initialization\n",
    "for layer_idx in (0, 2, 4):\n",
    "    resnet18_2.fc[layer_idx].weight.requires_grad = True\n",
    "    resnet18_2.fc[layer_idx].bias.requires_grad = True\n",
    "# resnet18_2.fc.weight.requires_grad = True\n",
    "# resnet18_2.fc.bias.requires_grad = True\n",
    "count_trainable_parameters(resnet18_2)\n",
    "# print(summary(resnet18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "915fa93f-998d-456d-8f7d-b49a55e45be1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Learning rate: 0.001000\n",
      "Training - Loss: 2.1468, Accuracy: 0.24, Runtime: 11.33\n",
      "Test - Loss: 1.9370, Accuracy: 0.32\n",
      "Epoch: 2, Learning rate: 0.001000\n",
      "Training - Loss: 1.8304, Accuracy: 0.35, Runtime: 11.59\n",
      "Test - Loss: 1.7798, Accuracy: 0.37\n",
      "Epoch: 3, Learning rate: 0.001000\n",
      "Training - Loss: 1.7404, Accuracy: 0.39, Runtime: 11.63\n",
      "Test - Loss: 1.7309, Accuracy: 0.39\n",
      "Epoch: 4, Learning rate: 0.001000\n",
      "Training - Loss: 1.7030, Accuracy: 0.40, Runtime: 11.32\n",
      "Test - Loss: 1.7252, Accuracy: 0.40\n",
      "Epoch: 5, Learning rate: 0.001000\n",
      "Training - Loss: 1.6922, Accuracy: 0.40, Runtime: 11.57\n",
      "Test - Loss: 1.6892, Accuracy: 0.40\n",
      "Epoch: 6, Learning rate: 0.001000\n",
      "Training - Loss: 1.6746, Accuracy: 0.41, Runtime: 11.62\n",
      "Test - Loss: 1.6982, Accuracy: 0.41\n",
      "Epoch: 7, Learning rate: 0.001000\n",
      "Training - Loss: 1.6667, Accuracy: 0.41, Runtime: 11.68\n",
      "Test - Loss: 1.6535, Accuracy: 0.42\n",
      "Epoch: 8, Learning rate: 0.001000\n",
      "Training - Loss: 1.6552, Accuracy: 0.41, Runtime: 11.71\n",
      "Test - Loss: 1.6710, Accuracy: 0.41\n",
      "Epoch: 9, Learning rate: 0.001000\n",
      "Training - Loss: 1.6471, Accuracy: 0.42, Runtime: 11.22\n",
      "Test - Loss: 1.6529, Accuracy: 0.41\n",
      "Epoch: 10, Learning rate: 0.001000\n",
      "Training - Loss: 1.6385, Accuracy: 0.42, Runtime: 11.46\n",
      "Test - Loss: 1.6446, Accuracy: 0.42\n",
      "Done! - Runtime: 186.73 seconds\n",
      "=========\n",
      "Accuracy for class: plane is 42.5 %\n",
      "Accuracy for class: car   is 57.1 %\n",
      "Accuracy for class: bird  is 29.0 %\n",
      "Accuracy for class: cat   is 33.3 %\n",
      "Accuracy for class: deer  is 37.5 %\n",
      "Accuracy for class: dog   is 35.5 %\n",
      "Accuracy for class: frog  is 57.1 %\n",
      "Accuracy for class: horse is 41.5 %\n",
      "Accuracy for class: ship  is 56.0 %\n",
      "Accuracy for class: truck is 35.6 %\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "resnet18_2_dict = dict(model=resnet18_2, criterion=criterion, device=device, lr=0.001, momentum=0.9,\n",
    "                       max_epochs=max_epochs, do_test=True)\n",
    "\n",
    "stats = train_loop(trainloader, valloader, **resnet18_2_dict)\n",
    "\n",
    "print(\"=========\")\n",
    "test_class(resnet18_2, device, criterion, valloader, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94050735-6b84-495d-8a9a-0e0a9de6a508",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Cambiare il learning rate dei layer finali oppure mettere trainable un layer di convoluzione interno e cambiargli learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79767d7-1fc8-47fa-a118-baa73f86d74d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63f3b136-feab-40b5-a1f5-e6aa10e6f8ac",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Model selection strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40eed69-e774-4e0b-9559-e8d71207fad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
